{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Data Science \"Salarios de los cientificos de datos\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desde que descubrí el mundo de la ciencia de datos, siempre he tenido una curiosidad insaciable por entender cómo las variables influyen en los resultados. En particular, me he preguntado: ¿Cuáles son las variables que más se correlacionan con el nivel de ingresos de un científico de datos? ¿El tamaño de la empresa tiene algo que ver con el nivel de ingresos?\n",
    "\n",
    "Para responder a estas preguntas, decidí embarcarme en un proyecto de wrangling de datos. Comencé con un dataframe de salarios de científicos de datos, pero sabía que necesitaba más información para enriquecer mis datos. Así que decidí utilizar una API para obtener datos adicionales.\n",
    "\n",
    "La API me proporcionó información valiosa sobre las empresas, como su tamaño y su ubicación. Con estos nuevos datos, pude enriquecer mi dataframe original y obtener una visión más completa del panorama.\n",
    "\n",
    "Una vez que tuve todos los datos que necesitaba, comencé el proceso de wrangling. Limpié los datos, manejé los valores perdidos y outliers, y preparé los datos para el análisis.\n",
    "\n",
    "Finalmente, llegó el momento de responder a mis hipótesis. Utilicé técnicas estadísticas para identificar las variables que más se correlacionaban con el nivel de ingresos. También analicé si el tamaño de la empresa tenía algún efecto en el nivel de ingresos.\n",
    "\n",
    "Este proyecto fue un viaje increíblemente enriquecedor. No sólo me permitió responder a mis preguntas, sino que también me dio una visión más profunda del campo de la ciencia de datos. Me hizo darme cuenta de que quiero seguir creciendo y aprendiendo en este campo, y estoy emocionado por lo que vendrá a continuación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalo el paquete python-dotenv en el entorno Python actual. Este paquete es útil para manejar archivos .env, que son una forma común y segura de almacenar configuraciones secretas o específicas del entorno (como claves API o contraseñas) para tu aplicación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\diego\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estoy utilizando este código para cargar dos claves API desde un archivo .env y almacenarlas en las variables api_key1 y api_key2. Esto es útil porque me permite mantener estas claves API fuera del código fuente, lo cual es una buena práctica para proteger información sensible. Ah si mismo el archivo en el que esta almacenadas las APIKEY esta incluido en un .gitignore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key1 = os.getenv(\"API_KEY_DI\")\n",
    "api_key2 = os.getenv(\"API_KEY_BEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 220 entries, 0 to 219\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   title         220 non-null    object \n",
      " 1   company_name  220 non-null    object \n",
      " 2   location      220 non-null    object \n",
      " 3   description   220 non-null    object \n",
      " 4   salaries      0 non-null      float64\n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 8.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Importación de librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import requests\n",
    "\n",
    "# Carga del dataset\n",
    "dataSet = '../data/jobs_data.csv'\n",
    "df = pd.read_csv(dataSet)\n",
    "\n",
    "# Resumen general del dataset\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este Dataframe fue obtenido en el trabajo anterior de conexiones con APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>salaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Audible, Inc.</td>\n",
       "      <td>Newark, NJ</td>\n",
       "      <td>Good storytelling starts with great listening....</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Internal Revenue Service</td>\n",
       "      <td>Huntsville, AL   (+36 others)</td>\n",
       "      <td>Click on \"Learn more about this agency\" button...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024 University Graduate - Data Science Engine...</td>\n",
       "      <td>Adobe</td>\n",
       "      <td>Biloxi, MS</td>\n",
       "      <td>Our Company\\r\\n\\r\\nChanging the world through ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist, Machine Learning (NLP)</td>\n",
       "      <td>Discord</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>Discord is looking for experienced and passion...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Director, Data Science - Retail Media+</td>\n",
       "      <td>The Home Depot</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Position Purpose:\\r\\n\\r\\nWe are actively seeki...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Senior Data Scientist, Product Growth</td>\n",
       "      <td>Jerry</td>\n",
       "      <td>Detroit, MI</td>\n",
       "      <td>We'd love to hear from you if you like:\\r\\n• M...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>(Intern) Enterprise Analytics Office Data Scie...</td>\n",
       "      <td>Nationwide Insurance and Financial Services</td>\n",
       "      <td>Hammond, IN</td>\n",
       "      <td>As a team member in the Finance and Internal A...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Staff Data Scientist</td>\n",
       "      <td>MongoDB</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>The worldwide data management software market ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Postdoctoral Scholar</td>\n",
       "      <td>The University of Chicago, Data Science Institute</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>The Data Science Institute (DSI) at the Univer...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>Director - Data Science (Remote)</td>\n",
       "      <td>Co-Op Financial Services</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>The Opportunity:\\r\\n\\r\\nWe are seeking a talen...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0                                       Data Scientist   \n",
       "1                                       Data Scientist   \n",
       "2    2024 University Graduate - Data Science Engine...   \n",
       "3        Senior Data Scientist, Machine Learning (NLP)   \n",
       "4               Director, Data Science - Retail Media+   \n",
       "..                                                 ...   \n",
       "215              Senior Data Scientist, Product Growth   \n",
       "216  (Intern) Enterprise Analytics Office Data Scie...   \n",
       "217                               Staff Data Scientist   \n",
       "218                               Postdoctoral Scholar   \n",
       "219                   Director - Data Science (Remote)   \n",
       "\n",
       "                                          company_name  \\\n",
       "0                                        Audible, Inc.   \n",
       "1                             Internal Revenue Service   \n",
       "2                                                Adobe   \n",
       "3                                              Discord   \n",
       "4                                       The Home Depot   \n",
       "..                                                 ...   \n",
       "215                                              Jerry   \n",
       "216        Nationwide Insurance and Financial Services   \n",
       "217                                            MongoDB   \n",
       "218  The University of Chicago, Data Science Institute   \n",
       "219                           Co-Op Financial Services   \n",
       "\n",
       "                               location  \\\n",
       "0                         Newark, NJ      \n",
       "1      Huntsville, AL   (+36 others)      \n",
       "2                         Biloxi, MS      \n",
       "3                             Anywhere    \n",
       "4                        Atlanta, GA      \n",
       "..                                  ...   \n",
       "215                      Detroit, MI      \n",
       "216                      Hammond, IN      \n",
       "217                San Francisco, CA      \n",
       "218                      Chicago, IL      \n",
       "219                       Austin, TX      \n",
       "\n",
       "                                           description  salaries  \n",
       "0    Good storytelling starts with great listening....       NaN  \n",
       "1    Click on \"Learn more about this agency\" button...       NaN  \n",
       "2    Our Company\\r\\n\\r\\nChanging the world through ...       NaN  \n",
       "3    Discord is looking for experienced and passion...       NaN  \n",
       "4    Position Purpose:\\r\\n\\r\\nWe are actively seeki...       NaN  \n",
       "..                                                 ...       ...  \n",
       "215  We'd love to hear from you if you like:\\r\\n• M...       NaN  \n",
       "216  As a team member in the Finance and Internal A...       NaN  \n",
       "217  The worldwide data management software market ...       NaN  \n",
       "218  The Data Science Institute (DSI) at the Univer...       NaN  \n",
       "219  The Opportunity:\\r\\n\\r\\nWe are seeking a talen...       NaN  \n",
       "\n",
       "[220 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se encontraron resultados de trabajos para Nueva York\n",
      "No se encontraron resultados de trabajos para Filadelfia\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '..data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Diego\\Desktop\\diego programacion\\jupyterNotebookDiego\\notebooks\\Desafio_wrangling_Matcovich.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Diego/Desktop/diego%20programacion/jupyterNotebookDiego/notebooks/Desafio_wrangling_Matcovich.ipynb#W4sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(jobs_data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Diego/Desktop/diego%20programacion/jupyterNotebookDiego/notebooks/Desafio_wrangling_Matcovich.ipynb#W4sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# Guarda el DataFrame como un archivo CSV\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Diego/Desktop/diego%20programacion/jupyterNotebookDiego/notebooks/Desafio_wrangling_Matcovich.ipynb#W4sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m df\u001b[39m.\u001b[39;49mto_csv(\u001b[39m'\u001b[39;49m\u001b[39m..data/jobs_data2.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)    \n",
      "File \u001b[1;32mc:\\Users\\Diego\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:3772\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3761\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m   3763\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3764\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[0;32m   3765\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3769\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[0;32m   3770\u001b[0m )\n\u001b[1;32m-> 3772\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[0;32m   3773\u001b[0m     path_or_buf,\n\u001b[0;32m   3774\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[0;32m   3775\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[0;32m   3776\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   3777\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   3778\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m   3779\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[0;32m   3780\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   3781\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   3782\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m   3783\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   3784\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[0;32m   3785\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[0;32m   3786\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[0;32m   3787\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[0;32m   3788\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   3789\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Diego\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1186\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1165\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1168\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1169\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1184\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[0;32m   1185\u001b[0m )\n\u001b[1;32m-> 1186\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1189\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\Diego\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:240\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    241\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilepath_or_buffer,\n\u001b[0;32m    242\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    243\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    244\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,\n\u001b[0;32m    245\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression,\n\u001b[0;32m    246\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[0;32m    247\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[0;32m    248\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[0;32m    250\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m    251\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[0;32m    257\u001b[0m     )\n\u001b[0;32m    259\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\Diego\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:737\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[39m# Only for write methods\u001b[39;00m\n\u001b[0;32m    736\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode \u001b[39mand\u001b[39;00m is_path:\n\u001b[1;32m--> 737\u001b[0m     check_parent_directory(\u001b[39mstr\u001b[39;49m(handle))\n\u001b[0;32m    739\u001b[0m \u001b[39mif\u001b[39;00m compression:\n\u001b[0;32m    740\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzstd\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    741\u001b[0m         \u001b[39m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Diego\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:600\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    598\u001b[0m parent \u001b[39m=\u001b[39m Path(path)\u001b[39m.\u001b[39mparent\n\u001b[0;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parent\u001b[39m.\u001b[39mis_dir():\n\u001b[1;32m--> 600\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39mrf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot save file into a non-existent directory: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mparent\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '..data'"
     ]
    }
   ],
   "source": [
    "# Define la URL\n",
    "url = 'https://serpapi.com/search'\n",
    "\n",
    "# Lista de todos los estados en los Estados Unidos\n",
    "estados = ['Nueva York', 'Miami', 'Los Angeles', 'Las Vegas', 'Hawaii', 'Washington DC', 'Boston', 'Orlando', 'San Francisco', 'Chicago', 'Atlanta', 'Filadelfia', 'Seattle', 'Dallas', 'Austin', 'Houston', 'Denver', 'Detroit', 'Minneapolis', 'Phoenix', 'San Diego', 'St. Louis', 'Tampa', 'Baltimore', 'Pittsburgh', 'Portland', 'Charlotte', 'Indianapolis', 'Kansas City', 'New Orleans', 'Cleveland', 'Sacramento', 'Cincinnati', 'Milwaukee', 'Honolulu', 'Salt Lake City', 'Raleigh', 'Nashville', 'Buffalo', 'Richmond','Louisville','Providence','Oklahoma City','Jacksonville','Memphis','Columbus','Las Vegas','Albuquerque','Tucson','Fresno']\n",
    "\n",
    "\n",
    "# Inicializa una lista vacía para almacenar los datos de los trabajos\n",
    "jobs_data = []\n",
    "\n",
    "# Haz una solicitud GET a la API para cada estado\n",
    "for estado in estados:\n",
    "    params = {\n",
    "        'engine': 'google_jobs',\n",
    "        'q': 'data science',  # Reemplaza esto con el título del trabajo que estás buscando\n",
    "        'location': estado,  # Cambia la ubicación a cada estado\n",
    "        'api_key': api_key2 ,  # Esta es la clave de API de SerpApi\n",
    "        'num': 10  # Solicita 10 resultados por página\n",
    "    }\n",
    "\n",
    "    # Haz una solicitud GET a la API\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    # Verifica si 'jobs_results' está en la respuesta\n",
    "    if 'jobs_results' in response.json():\n",
    "        # Extrae la información relevante de los resultados de la búsqueda\n",
    "        for job in response.json()['jobs_results']:\n",
    "            job_info = {\n",
    "                'title': job.get('title'),\n",
    "                'company_name': job.get('company_name'),\n",
    "                'location': job.get('location'),\n",
    "                'description': job.get('description'),\n",
    "                # Asegúrate de que el campo 'salaries' exista antes de intentar acceder a él\n",
    "                'salaries': job.get('salaries') if 'salaries' in job else None,\n",
    "            }\n",
    "            jobs_data.append(job_info)\n",
    "    else:\n",
    "        print(f\"No se encontraron resultados de trabajos para {estado}\")\n",
    "\n",
    "# Crea un DataFrame con los datos\n",
    "df = pd.DataFrame(jobs_data)\n",
    "\n",
    "# Guarda el DataFrame como un archivo CSV\n",
    "df.to_csv('..data/jobs_data2.csv', index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'description'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Diego\\Desktop\\diego programacion\\jupyterNotebookDiego\\notebooks\\Desafio_wrangling_Matcovich.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Diego/Desktop/diego%20programacion/jupyterNotebookDiego/notebooks/Desafio_wrangling_Matcovich.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mnan\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Diego/Desktop/diego%20programacion/jupyterNotebookDiego/notebooks/Desafio_wrangling_Matcovich.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Aplicamos la función a la columna 'description' y creamos una nueva columna 'salary'\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Diego/Desktop/diego%20programacion/jupyterNotebookDiego/notebooks/Desafio_wrangling_Matcovich.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39msalary\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mdescription\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mapply(extraer_numero)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Diego/Desktop/diego%20programacion/jupyterNotebookDiego/notebooks/Desafio_wrangling_Matcovich.ipynb#W5sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m df\n",
      "File \u001b[1;32mc:\\Users\\Diego\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Diego\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:349\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m--> 349\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n\u001b[0;32m    350\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    351\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'description'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Definimos una función para extraer el número después del símbolo '$'\n",
    "def extraer_numero(texto):\n",
    "    match = re.search(\"\\$([0-9,\\.]+)\", texto)\n",
    "    if match is not None:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Aplicamos la función a la columna 'description' y creamos una nueva columna 'salary'\n",
    "df['salary'] = df['description'].apply(extraer_numero)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "2820\n",
      "2150\n",
      "No se encontró el símbolo '$'\n",
      "4970\n",
      "No se encontró el símbolo '$'\n",
      "2457\n",
      "3552\n",
      "3878\n",
      "81\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "2820\n",
      "No se encontró el símbolo '$'\n",
      "4970\n",
      "No se encontró el símbolo '$'\n",
      "3878\n",
      "2237\n",
      "No se encontró el símbolo '$'\n",
      "3552\n",
      "735\n",
      "No se encontró el símbolo '$'\n",
      "81\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "4920\n",
      "4970\n",
      "No se encontró el símbolo '$'\n",
      "2150\n",
      "No se encontró el símbolo '$'\n",
      "81\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "5705\n",
      "No se encontró el símbolo '$'\n",
      "81\n",
      "No se encontró el símbolo '$'\n",
      "1919\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "3890\n",
      "4065\n",
      "5908\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "4100\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "4875\n",
      "No se encontró el símbolo '$'\n",
      "81\n",
      "2150\n",
      "No se encontró el símbolo '$'\n",
      "4970\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "4920\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "81\n",
      "No se encontró el símbolo '$'\n",
      "1812\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "2457\n",
      "4970\n",
      "No se encontró el símbolo '$'\n",
      "735\n",
      "4076\n",
      "4920\n",
      "2820\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "3552\n",
      "81\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "5933\n",
      "No se encontró el símbolo '$'\n",
      "4987\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "36\n",
      "81\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "2820\n",
      "No se encontró el símbolo '$'\n",
      "3880\n",
      "4970\n",
      "5705\n",
      "3878\n",
      "2150\n",
      "2820\n",
      "No se encontró el símbolo '$'\n",
      "81\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "5705\n",
      "No se encontró el símbolo '$'\n",
      "4970\n",
      "No se encontró el símbolo '$'\n",
      "5705\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "3552\n",
      "2150\n",
      "No se encontró el símbolo '$'\n",
      "81\n",
      "5705\n",
      "No se encontró el símbolo '$'\n",
      "3552\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "81\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "4076\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "3552\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "81\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "5705\n",
      "4174\n",
      "4970\n",
      "51\n",
      "3237\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "81\n",
      "No se encontró el símbolo '$'\n",
      "4278\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "4920\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "2457\n",
      "No se encontró el símbolo '$'\n",
      "4970\n",
      "No se encontró el símbolo '$'\n",
      "3878\n",
      "2820\n",
      "3552\n",
      "619\n",
      "No se encontró el símbolo '$'\n",
      "81\n",
      "5524\n",
      "4920\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "2237\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "3878\n",
      "5423\n",
      "81\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "4970\n",
      "4273\n",
      "5705\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "4216\n",
      "3103\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "3878\n",
      "No se encontró el símbolo '$'\n",
      "1772\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "4970\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "616\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "5705\n",
      "No se encontró el símbolo '$'\n",
      "No se encontró el símbolo '$'\n",
      "264\n",
      "3552\n",
      "81\n",
      "No se encontró el símbolo '$'\n",
      "4076\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "for i in range(len(df)):\n",
    "    match = re.search(\"\\$\", df.description[i])\n",
    "    if match is not None:\n",
    "        print(list(match.span())[0])\n",
    "    else:\n",
    "        print(\"No se encontró el símbolo '$'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We'd love to hear from you if you like:\n",
      "• Making a big impact with a Forbes Top Startup Employer\n",
      "• Working on products that have traction (40X revenue growth in 4 years | #1 rated app in the insurance comparison category...\n",
      "• Solving problems in a huge market ($2T market size)\n",
      "• Working closely with serial entrepreneurs and seasoned leaders who have scaled companies like Robinhood, Amazon, LinkedIn, Wayfair, SoFi, Microsoft, etc.\n",
      "\n",
      "About the opportunity:\n",
      "\n",
      "We are looking for a Senior Data Scientist to join our central data team and partner with one of our emerging product groups. Helping everyday, hard working Americans save time and money on their cars and creating a world class experience is what drives every decision we make as a company. Since launching our mobile app in 2019, we have amassed over 4M customers, expanded our product offerings to multiple categories and scaled our team 10X. Our data team fuels all of our business and product decisions through delivering analytical insights and building advanced models.\n",
      "\n",
      "Reporting to our VP of Business Operations and Analytics, you will leverage data to drive growth and retention for one of our emerging product groups (car maintenance marketplace or chatbot). You will perform analytical deep dives, develop and analyze experiments, build predictive models, and make recommendations that inform our product roadmap. Working with a brilliant team of product managers, product designers, software engineers, and key business leaders, you will play a big role in accelerating our growth and taking our customer experience to the next level.\n",
      "\n",
      "How you will make an impact:\n",
      "• Partner closely with our product managers, software engineers, product designers, and key business leaders to drive user growth and retention for our core insurance product\n",
      "• Design, run, and analyze A/B experiments on new and existing features; extract key insights, share learnings and make recommendations on next steps\n",
      "• Build key reports, dashboards, and predictive models to monitor the performance of our insurance business, and communicate analytical outcomes to our teams\n",
      "• Transform and refine raw production data for analytical needs\n",
      "• Continually improve our data governance and data consistency standards within our database\n",
      "• Work with data engineering team on data tracking, integrity, and security as needed\n",
      "• Work with other data scientists to evolve, optimize and integrate machine learning models\n",
      "\n",
      "Who you are:\n",
      "• Intellectually curious: You're not satisfied with surface level insights. You dive deep to understand how systems work, why people behave in certain ways and are intrinsically motivated to uncover root causes for issues or underlying reasons behind decisions.\n",
      "• Creative problem-solver: No challenge is too complex, no issue is too hard.\n",
      "• Data-driven: You're extremely analytical and live in data. At the same time, you're confident enough to make decisions when the data is limited.\n",
      "• Strong communicato\n"
     ]
    }
   ],
   "source": [
    "# inspeccion de donde puede estar el saladio dentro de descripcion\n",
    "num_fila = 215  # El número de la fila que quieres seleccionar\n",
    "nombre_columna = 'description'  # El nombre de la columna que quieres seleccionar\n",
    "\n",
    "# Usamos at para seleccionar el valor\n",
    "valor = df.at[num_fila, nombre_columna]\n",
    "\n",
    "# Ahora valor es una cadena de texto. Podemos extraer una subcadena así:\n",
    "inicio = 0  # La posición inicial desde donde quieres extraer\n",
    "fin = 3000  # La posición final hasta donde quieres extraer\n",
    "\n",
    "# Usamos la indexación de cadenas de texto para extraer la subcadena\n",
    "subcadena = valor[inicio:fin]\n",
    "\n",
    "print(subcadena)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Diego\\Desktop\\diego programacion\\jupyterNotebookDiego\\notebooks\\Desafio_wrangling_Matcovich.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Diego/Desktop/diego%20programacion/jupyterNotebookDiego/notebooks/Desafio_wrangling_Matcovich.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df\u001b[39m.\u001b[39misnull()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.isnull()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
